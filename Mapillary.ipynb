{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES\n",
    "\n",
    "# Mind map\n",
    "# https://miro.com/app/board/o9J_kwo5k8s=/\n",
    "\n",
    "# Prediction labels\n",
    "# [       0     ,      1    ,   2  ]\n",
    "# [\"pedestrian\" , \"bicycle\" , \"car\"]\n",
    "\n",
    "# Coordinate format: [longitude, latitude]\n",
    "\n",
    "# Time format used:\n",
    "# \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "\n",
    "# Sequence format: Geojson\n",
    "#     type\n",
    "#     properties:\n",
    "#       captured_at (start of sequence)\n",
    "#       coordinateProperties\n",
    "#         cas (camera angle between 0 and 360)\n",
    "#         image_keys\n",
    "#     geometry\n",
    "#       coordinates [longitude, latitude]\n",
    "\n",
    "# Image format: Geojson\n",
    "#    type\n",
    "#    properties:\n",
    "#       captured_at, \n",
    "#       camera_model, camera_make, ca, pano, seq_key, key, username, user_key\n",
    "#    geometry\n",
    "    \n",
    "\n",
    "# Potential features\n",
    "#     Average velocity\n",
    "#     Maximum velocity\n",
    "#     Maximum stop time (calculate time between neighbours points relative to avg speed)\n",
    "#     Possible to use CAS coordinate property to estimte slope and the difference in velocity?\n",
    "#     Smallest turn (small turn will indicate not a car road)\n",
    "#     Trajectory measurements\n",
    "#     length\n",
    "#     \n",
    "#     \n",
    "#     Image detection\n",
    "#       Traffic lights (number or boolean)\n",
    "#       Roundabouts (number or boolean)\n",
    "#       Bicycle tracks on the side\n",
    "#       Highway/number or lanes\n",
    "#       Sidewalk\n",
    "\n",
    "# Features columns\n",
    "# 0 =label, 1 = seq_id, 2 = avg_speed(m/s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import pandas\n",
    "from datetime import datetime, date\n",
    "from pprint import pprint as pp\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API requests to Mapillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapillary\n",
    "def requestImageById(image_key):\n",
    "    request = requests.get(\"https://a.mapillary.com/v3/images/\"+image_key+\"?client_id=\"+client_id)\n",
    "    return request.json()\n",
    "\n",
    "def requestSequencesByBbox(ul, lr):\n",
    "    # i prefer [lat, lng], so have to keep that in mind\n",
    "    # request of bbox is box=minx,miny,maxx,maxy=ul_lng, lr_lat, lr_lng, ul_lat\n",
    "    request = requests.get(f\"https://a.mapillary.com/v3/sequences?bbox={ul[1]},{lr[0]},{lr[1]},{ul[0]}&per_page=10000&client_id={client_id}\")\n",
    "    return request.json()\n",
    "\n",
    "def requestSequenceById(sequence_key):\n",
    "    request = requests.get(\"https://a.mapillary.com/v3/sequences/\"+sequence_key+\"?client_id=\"+client_id)\n",
    "    return request.json()\n",
    "\n",
    "def requestImagesBySequence(sequence_key):\n",
    "    request = requests.get(\"https://a.mapillary.com/v3/images/?sequence_keys=\"+sequence_key+\"&per_page=10000&client_id=\"+client_id)\n",
    "    return request.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial requests from API url (23.08.19)\n",
    "config = readJson(\"config.json\")\n",
    "client_id=config[\"client_id\"]\n",
    "\n",
    "# Current problem: only retrieves max 1000..\n",
    "area_data =requestSequencesByBbox(config[\"test_area\"][0], config[\"test_area\"][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def subtractTime(end, start):\n",
    "    return 0\n",
    "\n",
    "def distance(end, start):\n",
    "    end = [deg2rad(end[0]),deg2rad(end[1])]\n",
    "    start = [deg2rad(start[0]),deg2rad(start[1])]\n",
    "    \n",
    "    R =  6373000\n",
    "    lon1, lat1, lon2, lat2 = start[0], start[1], end[0], end[1]\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = (math.sin(dlat/2)**2)+math.cos(lat1)*math.cos(lat2)*math.sin(dlon/2)**2\n",
    "    c = 2*math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    return R*c\n",
    "\n",
    "def deg2rad(deg):\n",
    "    return deg*(math.pi/180)\n",
    "\n",
    "def readJson(file):\n",
    "    with open(file,\"r\") as f:\n",
    "        file=json.load(f)\n",
    "    return file\n",
    "\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def avg_speed_n_forward(sequence, start,n):\n",
    "    return 0\n",
    "\n",
    "# def getP2PFeatures(sequence):\n",
    "#     prev\n",
    "\n",
    "def seq_iteration_operations(points):\n",
    "    prev = 0\n",
    "    dist = 0\n",
    "    time = 0\n",
    "    max_speed = 0\n",
    "    for curr in range(1,len(points)):\n",
    "        curr_dist = distance(points[curr][\"geometry\"][\"coordinates\"], points[prev][\"geometry\"][\"coordinates\"])\n",
    "        curr_time = datetime.strptime(points[curr][\"properties\"][\"captured_at\"], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        prev_time = datetime.strptime(points[prev][\"properties\"][\"captured_at\"], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        delta_t = (prev_time-curr_time).total_seconds()\n",
    "        speed_between = 0 if delta_t==0.0 else curr_dist/delta_t\n",
    "        if(speed_between>max_speed):\n",
    "            max_speed = speed_between\n",
    "        dist+=curr_dist\n",
    "        time+=delta_t\n",
    "        prev=curr\n",
    "    avg_speed = 0 if time==0.0 else dist/time\n",
    "#     print(dist, time, max_speed, avg_speed)\n",
    "    #in meter\n",
    "    return (dist, avg_speed, max_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write features for an area\n",
    "def area_features(area, write=False, stop_early=False, sample_size=20):\n",
    "    num_seq = len(area[\"features\"])\n",
    "    print(f\"[INFO] {num_seq} sequences:\")\n",
    "    f = open(\"features.tsv\", \"w+\")\n",
    "    for num, seq in enumerate(area_data[\"features\"]):\n",
    "        if(stop_early==True and num>sample_size):\n",
    "            break\n",
    "        printProgressBar(num, num_seq)\n",
    "        label = 0\n",
    "        key=seq[\"properties\"][\"key\"]\n",
    "        images = requestImagesBySequence(key)[\"features\"]\n",
    "        num_points = len(images)\n",
    "        if(num_points < 2):\n",
    "            continue\n",
    "#         print(f\"Number of points in seq {key}: {num_points}\")\n",
    "        (dist, avg_speed, max_speed) = seq_iteration_operations(images)\n",
    "        \n",
    "        if(dist==0 or avg_speed==0):\n",
    "            continue\n",
    "        if(avg_speed>5):\n",
    "            label=2\n",
    "        elif(avg_speed>1.4):\n",
    "            label=1\n",
    "        if(write==True):\n",
    "            f.write(f\"{avg_speed}\\t{max_speed}\\t{dist}\\t{label}\\t{key}\\n\")\n",
    "    f.close()\n",
    "    print(\"[INFO] Done generating features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure train and test data\n",
    "class_names = [\"Pedestrian\", \"Bicycle\", \"Car\"]\n",
    "n_classes = len(class_names)\n",
    "def prep_data():\n",
    "    \n",
    "    features = np.genfromtxt(\"features.tsv\", delimiter=\"\\t\")\n",
    "    data = features[:,:-2]\n",
    "    labels = features[:,-2].astype(int)\n",
    "\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(data, labels, test_size=0.2, random_state=20)\n",
    "    \n",
    "    x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    y_train = lb.fit_transform(y_train)\n",
    "    y_test = lb.transform(y_test)\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape) \n",
    "    return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def train_model(x_train, x_test, y_train, y_test,epochs=10, lr=0.01):\n",
    "    model = Sequential()\n",
    "#     model.add(Dense(36, input_shape=(x_train.shape[1],), activation=\"sigmoid\"))\n",
    "#     model.add(Dense(18, activation=\"sigmoid\"))\n",
    "#     model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "#     model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr=lr),metrics=[\"accuracy\"])\n",
    "#     model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=1)\n",
    "    input_shape = (x_train.shape[1],1)\n",
    "    model.add(Conv1D(filters=64,kernel_size=2,input_shape=input_shape, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    print(\"[INFO] Training network...\")\n",
    "    model.fit(x_train, y_train, epochs=100, verbose=0)\n",
    "    print(\"[INFO] Done training\")\n",
    "    return model\n",
    "\n",
    "def eval_model(model):\n",
    "    _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Model accuracy:\",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616, 3, 1) (154, 3, 1) (616, 3) (154, 3)\n",
      "[INFO] Training network...\n",
      "[INFO] Done training\n",
      "Model accuracy: 0.7532467516985807\n"
     ]
    }
   ],
   "source": [
    "# area_features(area_data, write=True, stop_early=False, sample_size=100)\n",
    "(x_train, x_test, y_train, y_test) = prep_data()\n",
    "model = train_model(x_train, x_test, y_train, y_test, lr=0.01)\n",
    "eval_model(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
