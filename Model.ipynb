{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_data_to_labels(train, labels):\n",
    "    columns_names=list(train.columns) + list(labels.columns)\n",
    "    df = pd.DataFrame(np.zeros([labels.shape[0], train.shape[1]+1]), columns=columns_names, index=labels.index)\n",
    "    for _id, seq in df.iterrows():\n",
    "        for item in columns_names[:-1]:\n",
    "            if _id in train.index:     \n",
    "                seq[item] = train.at[_id, item]  \n",
    "            else:\n",
    "                continue\n",
    "        seq[\"label\"] = labels.at[_id,\"label\"]\n",
    "    print(df.shape, )\n",
    "    return df\n",
    "\n",
    "#Creating training data\n",
    "def create_training_data(train, test_size=0.25):\n",
    "    x_train = train[features]\n",
    "    y_train = train[\"label\"]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train, y_train,random_state=10, test_size=test_size)\n",
    "    x_train = x_train.to_numpy().reshape(x_train.shape[0],x_train.shape[1],1)\n",
    "    x_test = x_test.to_numpy().reshape(x_test.shape[0],x_test.shape[1],1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    y_train = onehot_encoder.fit_transform(y_train.to_numpy().reshape(y_train.shape[0],1))\n",
    "    y_test = onehot_encoder.fit_transform(y_test.to_numpy().reshape(y_test.shape[0],1))\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Structure train and test data\n",
    "class_names = [\"Pedestrian\", \"Bicycle\", \"Car\"]\n",
    "n_classes = len(class_names)\n",
    "\n",
    "raw_data = pd.read_csv(\"training_data/features.csv\").drop_duplicates(subset=[\"id\"],keep=\"first\").set_index(\"id\")\n",
    "labels = pd.read_csv(\"sequence_labels.csv\").drop_duplicates(subset=[\"id\"],keep=\"first\").set_index(\"id\")\n",
    "data = match_data_to_labels(raw_data, labels)\n",
    "features = data.columns.values[:-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = create_training_data(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_50 (Conv1D)           (None, 16, 1)             2         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 8, 1)              0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 100)               900       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 1,205\n",
      "Trainable params: 1,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Best estimator:<keras.wrappers.scikit_learn.KerasClassifier object at 0x7ffb5c0101d0>\n",
      "\n",
      "Best params:{'activation': 'tanh', 'batch_size': 10, 'epochs': 50, 'optimizer': 'Adadelta'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_model(optimizer=\"adam\", activation=\"relu\", loss='categorical_crossentropy'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=1,\n",
    "                     kernel_size=1,\n",
    "                     strides=1,\n",
    "                     input_shape=(x_train.shape[1],1), \n",
    "                     activation=activation))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def grid_search():\n",
    "\n",
    "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    # define the grid search parameters\n",
    "    optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "    activation = [\"relu\", \"softmax\", \"sigmoid\",\"tanh\"]\n",
    "    batch_size = [10, 20, 40, 60, 80, 100]\n",
    "    epochs = [10, 50, 100]\n",
    "    param_grid = dict(optimizer=optimizer, epochs=epochs, batch_size=batch_size, activation=activation)\n",
    "    \n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "    grid.fit(x_train, y_train)\n",
    "    \n",
    "    print(f\"Best estimator:{grid.best_estimator_}\\n\\nBest params:{grid.best_params_}\")\n",
    "    return grid\n",
    "\n",
    "\n",
    "\n",
    "model = grid_search()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(model):\n",
    "    _, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print(\"Model accuracy:\",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9400471847029727"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 788us/step\n",
      "Model accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "eval_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
